{"cells":[{"cell_type":"code","execution_count":1,"id":"659a84d9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21721,"status":"ok","timestamp":1690982163142,"user":{"displayName":"Alireza Abrehforoush","userId":"13066877178784666231"},"user_tz":-210},"id":"659a84d9","outputId":"f8de4906-f256-402a-e91e-a1dff4ec5daa"},"outputs":[],"source":["# !pip install git+https://github.com/alan-turing-institute/SigNet.git"]},{"cell_type":"code","execution_count":2,"id":"GhlpZTuhglp6","metadata":{"id":"GhlpZTuhglp6"},"outputs":[],"source":["import math\n","import random\n","import numpy as np\n","import pandas as pd\n","import networkx as nx\n","import scipy as sc\n","import tqdm\n","\n","from matplotlib import pyplot as plt\n","from signet.cluster import Cluster\n","from sklearn.model_selection import train_test_split\n","#from sklearn.metrics import adjusted_rand_score\n","from sklearn.metrics import confusion_matrix\n","#from sklearn.metrics import plot_confusion_matrix\n","#from sklearn.metrics import plot_roc_curve\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import precision_score\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","\n","tqdm.pandas()"]},{"cell_type":"code","execution_count":3,"id":"-pBl8nmmJHDd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":350302,"status":"ok","timestamp":1690982515068,"user":{"displayName":"Alireza Abrehforoush","userId":"13066877178784666231"},"user_tz":-210},"id":"-pBl8nmmJHDd","outputId":"b03dd7f6-32da-4093-f905-b604b99c9ec0"},"outputs":[],"source":["# # for google colab\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","#file_path = \"/content/drive/My Drive/Link Prediction/Datasets/soc-sign-epinions_modified.csv\""]},{"cell_type":"code","execution_count":4,"id":"6382090b","metadata":{"id":"6382090b"},"outputs":[],"source":["# reading the raw dataset which may contain duplicates, node ids out of range (id of nodes should be assigned from zero to number_of_nodes - 1)\n","#df_raw = pd.read_csv(\"Datasets/New_ Microsoft_ Excel_ Worksheet.csv\")\n","file_path = \"Datasets/soc-sign-epinions_modified.csv\"\n","df_raw = pd.read_csv(file_path)"]},{"cell_type":"code","execution_count":5,"id":"e3c3cd92","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":89,"status":"ok","timestamp":1690982515071,"user":{"displayName":"Alireza Abrehforoush","userId":"13066877178784666231"},"user_tz":-210},"id":"e3c3cd92","outputId":"2f644c8d-2ea5-45f9-c0a0-4655b9141590"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source</th>\n","      <th>target</th>\n","      <th>sign</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>130144</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5080</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>117</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>841367</th>\n","      <td>92808</td>\n","      <td>131814</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>841368</th>\n","      <td>131816</td>\n","      <td>131817</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>841369</th>\n","      <td>131819</td>\n","      <td>131820</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>841370</th>\n","      <td>131824</td>\n","      <td>131825</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>841371</th>\n","      <td>131826</td>\n","      <td>131827</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>841372 rows × 3 columns</p>\n","</div>"],"text/plain":["        source  target  sign\n","0            1       2    -1\n","1       130144       2     1\n","2         5080       3     1\n","3            3       4     1\n","4          117       4     1\n","...        ...     ...   ...\n","841367   92808  131814    -1\n","841368  131816  131817     1\n","841369  131819  131820    -1\n","841370  131824  131825     1\n","841371  131826  131827     1\n","\n","[841372 rows x 3 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df_raw"]},{"cell_type":"code","execution_count":6,"id":"73e49f09","metadata":{"id":"73e49f09"},"outputs":[],"source":["df_no_dup = df_raw.drop_duplicates(inplace = False)\n","df_no_dup = df_no_dup.reset_index(drop=True)"]},{"cell_type":"code","execution_count":7,"id":"44d62bca","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":74,"status":"ok","timestamp":1690982515073,"user":{"displayName":"Alireza Abrehforoush","userId":"13066877178784666231"},"user_tz":-210},"id":"44d62bca","outputId":"5238e998-ba58-4e65-ad6f-9e56fa0ed2a3","scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source</th>\n","      <th>target</th>\n","      <th>sign</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>130144</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5080</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>117</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>841367</th>\n","      <td>92808</td>\n","      <td>131814</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>841368</th>\n","      <td>131816</td>\n","      <td>131817</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>841369</th>\n","      <td>131819</td>\n","      <td>131820</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>841370</th>\n","      <td>131824</td>\n","      <td>131825</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>841371</th>\n","      <td>131826</td>\n","      <td>131827</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>841372 rows × 3 columns</p>\n","</div>"],"text/plain":["        source  target  sign\n","0            1       2    -1\n","1       130144       2     1\n","2         5080       3     1\n","3            3       4     1\n","4          117       4     1\n","...        ...     ...   ...\n","841367   92808  131814    -1\n","841368  131816  131817     1\n","841369  131819  131820    -1\n","841370  131824  131825     1\n","841371  131826  131827     1\n","\n","[841372 rows x 3 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df_no_dup"]},{"cell_type":"markdown","id":"913e5f55","metadata":{},"source":["#### حذف یال‌های دوتایی با سورس و تارگت قرینه و ساین مخالف یکدیگر"]},{"cell_type":"code","execution_count":8,"id":"d319cef6","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There exist two records with the specified condition:\n","          source_left  target_left  sign_left  source_right  target_right  \\\n","5180             5080         1683          1          1683          5080   \n","7865             5080         3178          1          3178          5080   \n","173235              6         1579         -1          1579             6   \n","218042              6         2244         -1          2244             6   \n","232976              6         2359         -1          2359             6   \n","...               ...          ...        ...           ...           ...   \n","95894147       100128        99989         -1         99989        100128   \n","95895656       105236       104631          1        104631        105236   \n","95896069       107869       107373          1        107373        107869   \n","95898048       116462       116463          1        116463        116462   \n","95898273       131122       118989          1        118989        131122   \n","\n","          sign_right  \n","5180              -1  \n","7865              -1  \n","173235             1  \n","218042             1  \n","232976             1  \n","...              ...  \n","95894147           1  \n","95895656          -1  \n","95896069          -1  \n","95898048          -1  \n","95898273          -1  \n","\n","[5406 rows x 6 columns]\n"]}],"source":["# code to check if there exist two records which the first record's source value equals the second's target and viceversa having differenct sign value. \n","merged_df = pd.merge(df_no_dup, df_no_dup, left_on='source', right_on='target', how='inner', suffixes=('_left', '_right'))\n","\n","# Filter rows based on the condition\n","filtered_df = merged_df[(merged_df['source_left'] == merged_df['target_right'])\n","                        & (merged_df['target_left'] == merged_df['source_right'])\n","                        & (merged_df['sign_left'] != merged_df['sign_right'])\n","                        ]\n","if not filtered_df.empty:\n","    print(\"There exist two records with the specified condition:\")\n","    print(filtered_df)\n","else:\n","    print(\"No records found with the specified condition.\")\n","\n"]},{"cell_type":"code","execution_count":9,"id":"238af68d","metadata":{},"outputs":[],"source":["# Iterate through the filtered_df and extract unique rows\n","values_to_drop = []\n","for index, row in filtered_df.iterrows():\n","    values_to_drop.append(\n","        {'source': row['source_left'], 'target': row['target_left'], 'sign': row['sign_left']}\n","    )\n","    values_to_drop.append(\n","        {'source': row['source_right'], 'target': row['target_right'], 'sign': row['sign_right']}\n","    )\n","\n","# Convert the list of dictionaries to a DataFrame\n","values_to_drop_df = pd.DataFrame(values_to_drop)\n","# Removing duplicates\n","values_to_drop_df.drop_duplicates(inplace=True)\n","\n","# Use boolean indexing to drop rows with exact values in multiple columns\n","merged = df_no_dup.merge(values_to_drop_df, how='left', indicator=True)\n","\n","# Filter out the rows that are in both DataFrames\n","nobidir_df = merged[merged['_merge'] == 'left_only'].drop(columns=['_merge'])\n","nobidir_df = nobidir_df.reset_index(drop=True)"]},{"cell_type":"code","execution_count":10,"id":"8d9c5a1a","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source</th>\n","      <th>target</th>\n","      <th>sign</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>130144</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5080</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>117</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>835961</th>\n","      <td>92808</td>\n","      <td>131814</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>835962</th>\n","      <td>131816</td>\n","      <td>131817</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>835963</th>\n","      <td>131819</td>\n","      <td>131820</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>835964</th>\n","      <td>131824</td>\n","      <td>131825</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>835965</th>\n","      <td>131826</td>\n","      <td>131827</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>835966 rows × 3 columns</p>\n","</div>"],"text/plain":["        source  target  sign\n","0            1       2    -1\n","1       130144       2     1\n","2         5080       3     1\n","3            3       4     1\n","4          117       4     1\n","...        ...     ...   ...\n","835961   92808  131814    -1\n","835962  131816  131817     1\n","835963  131819  131820    -1\n","835964  131824  131825     1\n","835965  131826  131827     1\n","\n","[835966 rows x 3 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["nobidir_df"]},{"cell_type":"code","execution_count":11,"id":"7ec87fd6","metadata":{},"outputs":[],"source":["# # add new edges having direction opposite of existing edges\n","# temp_df = nobidir_df.copy()\n","\n","# temp = temp_df['source'].copy()\n","# temp_df['source'] = temp_df['target']\n","# temp_df['target'] = temp\n","\n","# undirected_df = pd.concat([nobidir_df, temp_df], ignore_index=True)\n","\n","# # Append the new rows to the original DataFrame\n","# undirected_df.drop_duplicates(inplace=True)"]},{"cell_type":"code","execution_count":12,"id":"cf1c01ed","metadata":{},"outputs":[],"source":["# undirected_df"]},{"cell_type":"code","execution_count":13,"id":"05691ab6","metadata":{"id":"05691ab6"},"outputs":[],"source":["# function to assign new ids to nodes regarding keeping ids in zero to num_of_nodes - 1\n","def relabel(df):\n","    source_old_labels = df[\"source\"].drop_duplicates().to_numpy()\n","    #print(source_old_labels)\n","    target_old_labels = df[\"target\"].drop_duplicates().to_numpy()\n","    all_old_labels = np.union1d(source_old_labels, target_old_labels)\n","    index_map = dict(enumerate(all_old_labels))\n","    new_index_map = dict([(value, key) for key, value in index_map.items()])\n","    #print(index_map == new_index_map)\n","    new_df = df.copy()\n","    for index, row in new_df.iterrows():\n","        #print(row[\"source\"])\n","        row[\"source\"] = new_index_map[row[\"source\"]]\n","        row[\"target\"] = new_index_map[row[\"target\"]]\n","    return new_index_map, new_df"]},{"cell_type":"code","execution_count":14,"id":"12f8a5fc","metadata":{"id":"12f8a5fc"},"outputs":[],"source":["ind_map, df_relabled = relabel(nobidir_df)"]},{"cell_type":"markdown","id":"9ca26b10","metadata":{"id":"9ca26b10"},"source":["#### اگر طوقه داشته باشه دیتاست نباید از MultiDiGraph استفاده شود"]},{"cell_type":"code","execution_count":15,"id":"b69d8601","metadata":{"id":"b69d8601"},"outputs":[],"source":["main_graph = nx.DiGraph()\n","main_graph = nx.from_pandas_edgelist(df = df_relabled, source = 'source', target = 'target', edge_attr = 'sign', create_using = nx.DiGraph(), edge_key = 'sign')"]},{"cell_type":"code","execution_count":16,"id":"5dc371ca","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":88,"status":"ok","timestamp":1690982591922,"user":{"displayName":"Alireza Abrehforoush","userId":"13066877178784666231"},"user_tz":-210},"id":"5dc371ca","outputId":"807d336e-22f3-47e9-89ea-a7f48188223b","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["number of nodes G = 131761\n","number of edges G = 835966\n","Density of G: 4.8152423059125095e-05\n"]}],"source":["print('number of nodes G =', nx.number_of_nodes(main_graph) )\n","print('number of edges G =', nx.number_of_edges(main_graph) )\n","print('Density of G:', nx.density(main_graph))"]},{"cell_type":"markdown","id":"293c1bc7","metadata":{"id":"293c1bc7"},"source":["### توجه شود که اختلاف تعداد یال‎های گراف با سطرهای دیتافریم به دلیل وجود یال چندگانه یا طوقه در دیتا فریم است."]},{"cell_type":"code","execution_count":17,"id":"918de99e","metadata":{"id":"918de99e"},"outputs":[],"source":["def graphTrainTestSplit(G, df, train_size, positive_size = 0.8):\n","    # setting randomness seed\n","    random.seed(42)\n","    np.random.seed(42)\n","\n","\n","    G_train = G.copy()\n","    train_df = df.copy()\n","    test_df = df.copy()\n","    edges_no = nx.number_of_edges(G_train)\n","    test_size = 1 - train_size\n","\n","    # Get the indices of positive and negative labels\n","    positive_indices = train_df[train_df['sign'] == 1].index.to_list()\n","    negative_indices = train_df[train_df['sign'] == -1].index.to_list()\n","\n","    # Shuffle the indices randomly\n","    random.shuffle(positive_indices)\n","    random.shuffle(negative_indices)\n","\n","    # Calculate the number of positive and negative labels for test set\n","    negative_size = 1 - positive_size\n","    test_positive_count = int(test_size * edges_no * positive_size)\n","    test_negative_count = int(test_size * edges_no * negative_size)\n","    # test_positive_count = int(train_size * len(positive_indices))\n","    # test_negative_count = int(train_size * len(negative_indices))\n","    number_of_edges_left_for_removal = test_positive_count + test_negative_count\n","\n","    edges_to_remove = []  # List to store edges for removal\n","\n","    #print(\"number_of_edges_left_for_removal: \", number_of_edges_left_for_removal, 'test_positive_count:', test_positive_count, 'test_negative_count: ', test_negative_count)\n","\n","    while number_of_edges_left_for_removal > 0:\n","        edges = np.array(G_train.edges)\n","        chosen_edge = random.choice(edges)\n","        source = chosen_edge[0]\n","        target = chosen_edge[1]\n","\n","        if (G_train.degree[source] > 1 and G_train.degree[target] > 1):\n","            label = train_df.loc[(train_df['source'] == source) & (train_df['target'] == target), 'sign'].values[0]\n","\n","            # Check if the edge label matches the desired distribution\n","            if (label == 1 and test_positive_count > 0) or (label == -1 and test_negative_count > 0):\n","                if G_train.has_edge(source, target):\n","                    edges_to_remove.append((source, target))\n","                    G_train.remove_edge(source, target)\n","                    if label == 1:\n","                        test_positive_count -= 1\n","                    else:\n","                        test_negative_count -= 1\n","                    number_of_edges_left_for_removal -= 1\n","\n","    #print('edges_to_remove size: ', len(edges_to_remove))\n","    # Remove the corresponding rows from the train DataFrame\n","    # train_df = train_df.drop(train_df[(train_df['source'].isin([edge[0] for edge in edges_to_remove])) &  (train_df['target'].isin([edge[1] for edge in edges_to_remove]))].index)\n","\n","    mask = train_df[['source', 'target']].apply(tuple, axis=1).isin(edges_to_remove)\n","    train_df = train_df[~mask]\n","\n","    test_df = test_df.merge(train_df, how='left', indicator=True)\n","    test_df = test_df[test_df['_merge'] == 'left_only'].drop('_merge', axis=1)\n","\n","    return G_train, train_df, test_df\n"]},{"cell_type":"code","execution_count":18,"id":"5b9500d3","metadata":{"id":"5b9500d3"},"outputs":[],"source":["# def graphTrainTestSplit(G, df, train_size):\n","#     G_train = G.copy()\n","#     train_df = df.copy()\n","#     test_df = df.copy()\n","#     edges_no = nx.number_of_edges(G_train)\n","#     number_of_edges_left_for_removal = np.floor((1 - train_size) * edges_no)\n","#     while (number_of_edges_left_for_removal > 0):\n","#         edges = np.array(G_train.edges)\n","#         chosen_edge = random.choice(edges)\n","#         if (G_train.degree[chosen_edge[0]] > 1 and G_train.degree[chosen_edge[1]] > 1):\n","#             G_train.remove_edge(chosen_edge[0], chosen_edge[1])\n","\n","#             # Get indexes where name column has value\n","#             index_names = train_df.index[(train_df['source'] == chosen_edge[0]) & (train_df['target'] == chosen_edge[1])]\n","#             # Delete these row indexes from dataFrame\n","#             train_df.drop(index_names, inplace = True)\n","\n","#             number_of_edges_left_for_removal -= 1\n","#     test_df = test_df.merge(train_df, how='left', indicator=True)\n","#     test_df = test_df[test_df['_merge'] == 'left_only'].drop('_merge', axis=1)\n","#     return G_train, train_df, test_df"]},{"cell_type":"code","execution_count":19,"id":"7499a852","metadata":{"id":"7499a852"},"outputs":[],"source":["train_graph, train_df, test_df = graphTrainTestSplit(main_graph, df_relabled, 0.99974327645797578241253571547425)"]},{"cell_type":"code","execution_count":20,"id":"0e59b105","metadata":{},"outputs":[],"source":["# function to add negative and positive weight columns to the dataframe\n","\n","def labelPosWeight (row):\n","   if row['sign'] == 1 :\n","      return 1\n","   else:\n","      return 0\n","\n","def labelNegWeight (row):\n","   if row['sign'] == -1 :\n","      return 1\n","   else:\n","      return 0"]},{"cell_type":"code","execution_count":21,"id":"834def6d","metadata":{},"outputs":[],"source":["train_df['pos_weight'] = train_df.apply (lambda row: labelPosWeight(row), axis=1)\n","train_df['neg_weight'] = train_df.apply (lambda row: labelNegWeight(row), axis=1)"]},{"cell_type":"code","execution_count":22,"id":"5wwEwNTAMBYh","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":53,"status":"ok","timestamp":1690983027014,"user":{"displayName":"Alireza Abrehforoush","userId":"13066877178784666231"},"user_tz":-210},"id":"5wwEwNTAMBYh","outputId":"6023cae8-227e-4681-9e90-0591c5820fcd"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source</th>\n","      <th>target</th>\n","      <th>sign</th>\n","      <th>pos_weight</th>\n","      <th>neg_weight</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>130076</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5076</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>116</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>835961</th>\n","      <td>92753</td>\n","      <td>131746</td>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>835962</th>\n","      <td>131748</td>\n","      <td>131749</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>835963</th>\n","      <td>131751</td>\n","      <td>131752</td>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>835964</th>\n","      <td>131756</td>\n","      <td>131757</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>835965</th>\n","      <td>131758</td>\n","      <td>131759</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>835753 rows × 5 columns</p>\n","</div>"],"text/plain":["        source  target  sign  pos_weight  neg_weight\n","0            0       1    -1           0           1\n","1       130076       1     1           1           0\n","2         5076       2     1           1           0\n","3            2       3     1           1           0\n","4          116       3     1           1           0\n","...        ...     ...   ...         ...         ...\n","835961   92753  131746    -1           0           1\n","835962  131748  131749     1           1           0\n","835963  131751  131752    -1           0           1\n","835964  131756  131757     1           1           0\n","835965  131758  131759     1           1           0\n","\n","[835753 rows x 5 columns]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["train_df"]},{"cell_type":"code","execution_count":23,"id":"-ESpFWBXrPFy","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":50,"status":"ok","timestamp":1690983027016,"user":{"displayName":"Alireza Abrehforoush","userId":"13066877178784666231"},"user_tz":-210},"id":"-ESpFWBXrPFy","outputId":"d1a5b345-1ddb-43b4-a33a-934b55aa11cf"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source</th>\n","      <th>target</th>\n","      <th>sign</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3540</th>\n","      <td>2434</td>\n","      <td>25</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5832</th>\n","      <td>48736</td>\n","      <td>25</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>13129</th>\n","      <td>34227</td>\n","      <td>155</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14915</th>\n","      <td>23591</td>\n","      <td>167</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>19034</th>\n","      <td>44841</td>\n","      <td>247</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>826573</th>\n","      <td>17385</td>\n","      <td>122928</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>826939</th>\n","      <td>17057</td>\n","      <td>123049</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>827188</th>\n","      <td>1117</td>\n","      <td>123233</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>827208</th>\n","      <td>17066</td>\n","      <td>123233</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>834857</th>\n","      <td>5638</td>\n","      <td>130528</td>\n","      <td>-1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>213 rows × 3 columns</p>\n","</div>"],"text/plain":["        source  target  sign\n","3540      2434      25     1\n","5832     48736      25    -1\n","13129    34227     155     1\n","14915    23591     167     1\n","19034    44841     247     1\n","...        ...     ...   ...\n","826573   17385  122928     1\n","826939   17057  123049     1\n","827188    1117  123233    -1\n","827208   17066  123233    -1\n","834857    5638  130528    -1\n","\n","[213 rows x 3 columns]"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["test_df"]},{"cell_type":"code","execution_count":24,"id":"92992895","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["number of nodes G = 131761\n","number of edges G = 835753\n","Density of G: 4.8140154060013177e-05\n"]}],"source":["print('number of nodes G =', nx.number_of_nodes(train_graph) )\n","print('number of edges G =', nx.number_of_edges(train_graph) )\n","print('Density of G:', nx.density(train_graph))"]},{"cell_type":"code","execution_count":25,"id":"b618455f","metadata":{},"outputs":[],"source":["def linePrepender(filename, line):\n","    with open(filename, 'r+') as f:\n","        content = f.read()\n","        f.seek(0, 0)\n","        f.write(line.rstrip('\\r\\n') + '\\n' + content)"]},{"cell_type":"code","execution_count":26,"id":"8cb9beee","metadata":{},"outputs":[],"source":["soc_df = train_df[['source', 'target', 'pos_weight', 'neg_weight']]\n","soc_df.to_csv(\"Datasets\\soc.tsv\", index = False, header = False, sep = '\\t')\n","linePrepender(\"Datasets\\soc.tsv\", str(nx.number_of_nodes(train_graph)) + '\\t' + str(nx.number_of_edges(train_graph)))"]},{"cell_type":"code","execution_count":null,"id":"dbd49f68","metadata":{},"outputs":[],"source":["train_df"]},{"cell_type":"code","execution_count":null,"id":"132320df","metadata":{},"outputs":[],"source":["test_df"]},{"cell_type":"code","execution_count":null,"id":"OkWA6V5GO91U","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48,"status":"ok","timestamp":1690983027017,"user":{"displayName":"Alireza Abrehforoush","userId":"13066877178784666231"},"user_tz":-210},"id":"OkWA6V5GO91U","outputId":"100ac294-c903-4800-d3b9-7832436e8dc9"},"outputs":[],"source":["num_duplicates = test_df.duplicated().sum()\n","print(\"Number of duplicates:\", num_duplicates)\n"]},{"cell_type":"code","execution_count":null,"id":"451b9c43","metadata":{"id":"451b9c43"},"outputs":[],"source":["rows = train_df.loc[:, \"source\"].to_numpy()\n","cols = train_df.loc[:, \"target\"].to_numpy()\n","sign = train_df.loc[:, \"sign\"].to_numpy()"]},{"cell_type":"code","execution_count":null,"id":"3ec1c649","metadata":{"id":"3ec1c649"},"outputs":[],"source":["p_rows = [rows[i] for i in range(len(rows)) if sign[i] == 1]\n","p_cols = [cols[i] for i in range(len(cols)) if sign[i] == 1]\n","p_data = np.ones(len(p_rows))\n","\n","n_rows = [rows[i] for i in range(len(rows)) if sign[i] == -1]\n","n_cols = [cols[i] for i in range(len(cols)) if sign[i] == -1]\n","n_data = np.ones(len(n_rows))"]},{"cell_type":"code","execution_count":null,"id":"a53631fe","metadata":{"id":"a53631fe"},"outputs":[],"source":["nodes_no = nx.number_of_nodes(train_graph)\n","edges_no = nx.number_of_edges(train_graph)"]},{"cell_type":"code","execution_count":null,"id":"18644208","metadata":{"id":"18644208","scrolled":true},"outputs":[],"source":["A_p = sc.sparse.csc_matrix((p_data, (p_rows, p_cols)), shape = (nodes_no , nodes_no))\n","A_n = sc.sparse.csc_matrix((n_data, (n_rows, n_cols)), shape = (nodes_no , nodes_no))"]},{"cell_type":"code","execution_count":null,"id":"4a961ac9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":71,"status":"ok","timestamp":1690983029104,"user":{"displayName":"Alireza Abrehforoush","userId":"13066877178784666231"},"user_tz":-210},"id":"4a961ac9","outputId":"860445df-1348-4874-ff83-f834a5bd4e36"},"outputs":[],"source":["print(p_data.shape)\n","print(n_data.shape)"]},{"cell_type":"markdown","id":"0e56cf49","metadata":{"id":"0e56cf49"},"source":["# اینجاااااااااااااااااااااااااااااااااااااااااااااااااااااا"]},{"cell_type":"code","execution_count":null,"id":"3603fa90","metadata":{"id":"3603fa90"},"outputs":[],"source":["def getNeighborsOfANode(graph, node):\n","    x = []\n","    for v in graph.nodes():\n","        if ((v, node) in graph.edges()):\n","            x.append(v)\n","    return np.array(x)"]},{"cell_type":"code","execution_count":null,"id":"d60c6603","metadata":{"id":"d60c6603"},"outputs":[],"source":["# def NodeswithoutInAndOutneighbors(G, sign_tag = 'sign'):\n","#     nodes_no = nx.number_of_nodes(G)\n","#     sign_map = nx.get_edge_attributes(G, sign_tag)\n","#     n = 0\n","#     for u in G.nodes():\n","#         for v in G.nodes():\n","#             #print(\"u: \", u, \", v: \", v)\n","#             if (u != v):\n","#                 u_neighbors = set(G.adj[u])\n","#                 v_neighbors = set(G.adj[v])\n","#                 uv_neighbors = list(u_neighbors.intersection(v_neighbors))\n","#                 u_inneighbors = set(getNeighborsOfANode(G, u))\n","#                 v_inneighbors = set(getNeighborsOfANode(G, v))\n","#                 uv_inneighbors = list(u_inneighbors.intersection(v_inneighbors))\n","#                 if (len(uv_neighbors) + len(uv_inneighbors)) == 0 and (u,v) in G.edges():\n","#                     n = n+1\n","#                     print(\"(u,v):\" , (u,v))\n","#     return n"]},{"cell_type":"code","execution_count":null,"id":"8f6898d1","metadata":{"id":"8f6898d1"},"outputs":[],"source":["#c = Cluster((A_p, A_n))"]},{"cell_type":"code","execution_count":null,"id":"6e7b7ea4","metadata":{"id":"6e7b7ea4"},"outputs":[],"source":["def getClusters(G, k, A_p, A_n):\n","    c = Cluster((A_p, A_n))\n","    #spec_clus = c.spectral_cluster_adjacency(k = 5, normalisation = 'sym_sep', eigens = None, mi = None)\n","    spec_clus = c.spectral_cluster_bnc(k = 5, normalisation='sym', eigens=None, mi=None)\n","    clusters = []\n","    for j in range(k):\n","        clusters.append([i for i in G.nodes() if spec_clus[int(i - 1)] == j])\n","    return np.array(clusters, dtype = np.ndarray)"]},{"cell_type":"code","execution_count":null,"id":"d8c331dd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13128,"status":"ok","timestamp":1690983042178,"user":{"displayName":"Alireza Abrehforoush","userId":"13066877178784666231"},"user_tz":-210},"id":"d8c331dd","outputId":"5676bfa3-8b03-4243-a138-84bf201b859a"},"outputs":[],"source":["main_clusters = getClusters(train_graph, 5, A_p, A_n)\n","cluster1 = main_clusters[0]\n","cluster2 = main_clusters[1]\n","cluster3 = main_clusters[2]\n","cluster4 = main_clusters[3]\n","cluster5 = main_clusters[4]"]},{"cell_type":"code","execution_count":null,"id":"7e3f0631","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":151,"status":"ok","timestamp":1690983042201,"user":{"displayName":"Alireza Abrehforoush","userId":"13066877178784666231"},"user_tz":-210},"id":"7e3f0631","outputId":"38b084cb-81e4-4028-df6c-2ddfec6d852e"},"outputs":[],"source":["print(len(cluster1))\n","print(len(cluster2))\n","print(len(cluster3))\n","print(len(cluster4))\n","print(len(cluster5))"]},{"cell_type":"code","execution_count":null,"id":"a74788dc","metadata":{"id":"a74788dc"},"outputs":[],"source":["def getCommonNeighbors(G, cl1, cl2):\n","    x = set([])\n","    for i in cl1:\n","        x = x.union(set(G.adj[i]))\n","    #print('x: ', x)\n","    y = set([])\n","    for j in cl2:\n","        y = y.union(set(G.adj[j]))\n","    #print('y: ', y)\n","    return list(x.intersection(y))"]},{"cell_type":"code","execution_count":null,"id":"031c1e03","metadata":{"id":"031c1e03"},"outputs":[],"source":["def locationOfANode(clusters, u):\n","    n = clusters.shape[0]\n","    x = np.zeros(n)\n","    r = -1\n","    for i in range(n):\n","        if u in clusters[i]:\n","            r = i\n","    return r"]},{"cell_type":"code","execution_count":null,"id":"165dfc34","metadata":{"id":"165dfc34"},"outputs":[],"source":["\n","def locationOfArrayOfNode(clusters, U):\n","    x = np.zeros(len(U))\n","    for i in range(len(x)):\n","        x[i] = locationOfANode(clusters, U[i])\n","    return x"]},{"cell_type":"code","execution_count":null,"id":"8ee81b85","metadata":{"id":"8ee81b85"},"outputs":[],"source":["def getClusterSimiliarity(G, source_cluster, common_neighbors, sign_tag = 'sign'):\n","    #print('common_neighbors: ', common_neighbors)\n","    sign_map = nx.get_edge_attributes(G, sign_tag)\n","    epsilon = 10 ** (-5)\n","    y = []\n","    for v in common_neighbors:\n","        # adding an epsilon to prevent mean of an empty array\n","        #x = [epsilon]\n","        x = []\n","        for u in source_cluster:\n","            if (u, v) in G.edges():\n","                x.append(sign_map[(u, v)])\n","                #print(\"u\", u , \"v\" , v)\n","        y.append(np.mean(np.array(x)))\n","    return np.array(y)"]},{"cell_type":"markdown","id":"60ec2a0e","metadata":{"id":"60ec2a0e"},"source":["##################"]},{"cell_type":"code","execution_count":null,"id":"06c614c8","metadata":{"id":"06c614c8"},"outputs":[],"source":["# main function to calculate the similiarity between two clusters\n","def getInterClusterSimiliarity(G, cl1, cl2, common_neighbors):\n","   y1 = getClusterSimiliarity(G, cl1, common_neighbors)\n","   y2 = getClusterSimiliarity(G, cl2, common_neighbors)\n","\n","   # if (y1.size == 0):\n","   #    print('y1: ', y1)\n","   #    print('###', common_neighbors)\n","   # if (y2.size == 0):\n","   #    print('y2: ', y2)\n","   #    print('###', common_neighbors)\n","\n","   alpha = np.dot(y1.T, y2)\n","\n","   ##first approach\n","   beta = np.dot(y1.T, y1)\n","   gamma = np.dot(y2.T, y2)\n","   if (beta * gamma < 0):\n","      print('it\"s negative: ', beta * gamma)\n","   epsilon = 10 ** (-5)\n","   #return alpha / (np.sqrt((beta * gamma)) + epsilon)\n","   return alpha / (np.sqrt((beta * gamma)))\n","\n","   ##second approach\n","   #return alpha / len(common_neighbors)"]},{"cell_type":"code","execution_count":null,"id":"bee73e85","metadata":{"id":"bee73e85"},"outputs":[],"source":["# # calculates similiarities between each two clusters and returns a matrix\n","# def getAllSimiliaritiesBetweenClusters(G, clusters):\n","#     clusters_no = clusters.shape[0]\n","#     similiarities = np.zeros(shape = (clusters_no, clusters_no))\n","#     for i in range(clusters_no):\n","#         for j in range(i, clusters_no):\n","#             common_neighbors = getCommonNeighbors(G, clusters[i], clusters[j])\n","#             current_similiarity = getInterClusterSimiliarity(G, clusters[i], clusters[j], common_neighbors)\n","#             # similiarities[i][j] = similiarities[j][i] = current_similiarity\n","#             if len(common_neighbors) == 0:\n","#                 print('i:', clusters[i])\n","#                 print('j:', clusters[j])\n","#             if (math.isnan(current_similiarity)):\n","#                 similiarities[i][j] = similiarities[j][i] = 0\n","#             else:\n","#                 similiarities[i][j] = similiarities[j][i] = current_similiarity\n","#     return similiarities"]},{"cell_type":"code","execution_count":null,"id":"e880f85a","metadata":{"id":"e880f85a"},"outputs":[],"source":["# Calculates similarities between each two clusters and returns a matrix\n","def getAllSimilaritiesBetweenClusters(G, clusters):\n","    clusters_no = clusters.shape[0]\n","    similiarities = np.zeros(shape=(clusters_no, clusters_no))\n","    total_iterations = clusters_no * (clusters_no + 1) // 2  # Total number of iterations for progress bar\n","\n","    with tqdm(total=total_iterations, desc=\"Calculating similarities\") as pbar:\n","        for i in range(clusters_no):\n","            for j in range(i, clusters_no):\n","                if i == j:\n","                    similiarities[i][j] = 1\n","                else:\n","                    common_neighbors = getCommonNeighbors(G, clusters[i], clusters[j])\n","                    current_similarity = getInterClusterSimiliarity(G, clusters[i], clusters[j], common_neighbors)\n","\n","                    if len(common_neighbors) == 0:\n","                        print('i:', clusters[i])\n","                        print('j:', clusters[j])\n","                    if math.isnan(current_similarity):\n","                        similiarities[i][j] = similiarities[j][i] = 0\n","                    else:\n","                        similiarities[i][j] = similiarities[j][i] = current_similarity\n","\n","                pbar.update(1)  # Update the progress bar\n","\n","    return similiarities"]},{"cell_type":"code","execution_count":null,"id":"192ae994","metadata":{"id":"192ae994"},"outputs":[],"source":["common_neighbors = getCommonNeighbors(train_graph, cluster1, cluster2)\n","similarity = getInterClusterSimiliarity(train_graph, cluster1, cluster2, common_neighbors)\n","similarity"]},{"cell_type":"code","execution_count":null,"id":"3e377cba","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":183},"executionInfo":{"elapsed":56,"status":"error","timestamp":1691008609893,"user":{"displayName":"Alireza Abrehforoush","userId":"13066877178784666231"},"user_tz":-210},"id":"3e377cba","outputId":"fbaf7bf4-e65c-447e-fb72-24860a745b20"},"outputs":[],"source":["matrix_of_similarity = getAllSimilaritiesBetweenClusters(train_graph, main_clusters)\n","matrix_of_similarity"]},{"cell_type":"code","execution_count":null,"id":"b4a0b229","metadata":{},"outputs":[],"source":["#the matrix for test set of size 215 and random seed 42\n","# matrix_of_similarity = np.array([\n","#         [1.  , 0.83, 0.81, 0.8 , 0.81],\n","#         [0.83, 1.  , 0.81, 0.79, 0.8 ],\n","#         [0.81, 0.81, 1.  , 0.81, 0.82],\n","#         [0.8 , 0.79, 0.81, 1.  , 0.76],\n","#         [0.81, 0.8 , 0.82, 0.76, 1.  ]])\n","\n","#the matrix for test set of size 215 and random seed 42 with (i, j, 1), (j, i, -1) removed\n","# array([[1.  , 0.8 , 0.82, 0.84, 0.82],\n","#        [0.8 , 1.  , 0.82, 0.84, 0.82],\n","#        [0.82, 0.82, 1.  , 0.82, 0.83],\n","#        [0.84, 0.84, 0.82, 1.  , 0.85],\n","#        [0.82, 0.82, 0.83, 0.85, 1.  ]])"]},{"cell_type":"code","execution_count":null,"id":"0cb4e156","metadata":{"id":"0cb4e156"},"outputs":[],"source":["def signPrediction(G, main_clusters, all_similiarities, k, u, v, threshold, w1, sign_tag = \"sign\"):\n","    sign_map = nx.get_edge_attributes(G, sign_tag)\n","    #main_clusters = getClusters(G, k)\n","\n","    u_c = locationOfANode(main_clusters, u)\n","    u_v = locationOfANode(main_clusters, v)\n","    cl1 = main_clusters[u_c]\n","    cl2 = main_clusters[u_v]\n","    #s_AB = getCommonNeighbors(G, cl1, cl2)\n","    #print(s_AB)\n","    S = getNeighborsOfANode(G, v)\n","    S_c = locationOfArrayOfNode(main_clusters, S)\n","    n = len(S)\n","    x = np.zeros(n)\n","    for i in range(n):\n","        #x[i] = getInterClusterSimiliarity(main_clusters[u_c], main_clusters[int(S_c[i])], s_AB)\n","        x[i] = all_similiarities[u_c][int(S_c[i])]\n","        #print('main_clusters_u_c: ', main_clusters[u_c])\n","        #print('main_clusters_int: ', main_clusters[int(S_c[i])])\n","        #print('s_AB: ', s_AB)\n","        #print('x[i]' , x[i]  )\n","\n","        if locationOfANode(main_clusters, u) == locationOfANode(main_clusters, S_c[i]):\n","            x[i] = w1 * x[i]\n","        else:\n","            x[i] = (1 - w1) * x[i]\n","\n","    r = np.zeros(n)\n","    for i in range(n):\n","        r[i] = sign_map[(S[i], v)]\n","    #print('x: ', x)\n","    #print('r: ', r)\n","    #if (np.sum(x) == 0):\n","    #    print('it is zero')\n","    epsilon = 10 ** (-5)\n","    #result = (np.dot(x.T, r)) / (np.sum(x) + epsilon)\n","    result = (np.dot(x.T, r)) / (np.sum(x))\n","    if result > threshold:\n","        return 1\n","    else:\n","        return -1"]},{"cell_type":"code","execution_count":null,"id":"b7784493","metadata":{"id":"b7784493"},"outputs":[],"source":["# from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":null,"id":"ec8bd279","metadata":{"id":"ec8bd279"},"outputs":[],"source":["# # Create a new column 'sign prediction' in test_df with sign predictions\n","# def calculateSignPredictions(train_graph, main_clusters, test_df):\n","#     with tqdm(total=len(test_df), desc=\"Calculating sign predictions\", bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}') as pbar:\n","#         test_df['sign prediction'] = test_df.apply(lambda row: signPrediction(train_graph, main_clusters, matrix_of_similarity, 5, row['source'], row['target'], 0, 0.75), axis=1)\n","#         pbar.update(len(test_df))  # Update the progress bar to complete\n","\n","#     return test_df\n"]},{"cell_type":"code","execution_count":null,"id":"7b770bf8","metadata":{"id":"7b770bf8"},"outputs":[],"source":["# Create a new column 'sign prediction' in test_df with sign predictions\n","def calculateSignPredictions(train_graph, main_clusters, test_df, w):\n","    new_test_df = test_df.copy()\n","    new_test_df['sign prediction'] = new_test_df.progress_apply(lambda row: signPrediction(train_graph, main_clusters, matrix_of_similarity, 5, row['source'], row['target'], 0.7, w), axis=1)\n","    return new_test_df\n"]},{"cell_type":"code","execution_count":null,"id":"cd8ae6dd","metadata":{"id":"cd8ae6dd","scrolled":false},"outputs":[],"source":["zz = np.zeros(test_df.shape[0])\n","# Call the function with the required parameters\n","new_test_df = calculateSignPredictions(train_graph, main_clusters, test_df, 0.5)\n","confusion_matrix(new_test_df['sign'], new_test_df['sign prediction'])\n","acc_temp = accuracy_score(new_test_df['sign'], new_test_df['sign prediction'],  normalize=True, sample_weight=None)\n","f_temp = f1_score(new_test_df['sign'], new_test_df['sign prediction'])"]},{"cell_type":"code","execution_count":null,"id":"197eef23","metadata":{"id":"197eef23"},"outputs":[],"source":["print(acc_temp)\n","print(f_temp)"]},{"cell_type":"code","execution_count":null,"id":"e5dc47b9","metadata":{"id":"e5dc47b9"},"outputs":[],"source":["# plt.hist(test_df['sign'])\n","\n","# # Set the labels and title of the histogram\n","# plt.xlabel('Sign')\n","# plt.ylabel('Frequency')\n","# plt.title('Histogram of Sign Values')\n","\n","# # Display the histogram\n","# plt.show()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"97d16830","metadata":{"id":"97d16830"},"outputs":[],"source":["acc_y = []\n","f_y = []\n","for w in [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]:\n","    new_test_df = calculateSignPredictions(train_graph, main_clusters, test_df, w)\n","    confusion_matrix(new_test_df['sign'], new_test_df['sign prediction'])\n","    acc_temp = accuracy_score(new_test_df['sign'], new_test_df['sign prediction'],  normalize=True, sample_weight=None)\n","    f_temp = f1_score(new_test_df['sign'], new_test_df['sign prediction'])\n","    print('accuracy:', acc_temp, 'f1:', f_temp)\n","    acc_y.append(acc_temp)\n","    f_y.append(f_y)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":5}
