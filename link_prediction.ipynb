{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "659a84d9",
      "metadata": {
        "id": "659a84d9"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import scipy as sc\n",
        "import pyccalg as ca\n",
        "from tqdm import tqdm\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from signet.cluster import Cluster\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn.metrics import adjusted_rand_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "#from sklearn.metrics import plot_roc_curve\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "-pBl8nmmJHDd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pBl8nmmJHDd",
        "outputId": "5d3caeb1-5ab2-4c61-d315-6c704fe4a6bb"
      },
      "outputs": [],
      "source": [
        "# for google colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6382090b",
      "metadata": {
        "id": "6382090b"
      },
      "outputs": [],
      "source": [
        "# reading the raw dataset which may contain duplicates, node ids out of range (id of nodes should be assigned from zero to number_of_nodes - 1)\n",
        "#df_raw = pd.read_csv(\"Datasets/New_ Microsoft_ Excel_ Worksheet.csv\")\n",
        "df_raw = pd.read_csv(\"Datasets/soc-sign-epinions_modified.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e3c3cd92",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "e3c3cd92",
        "outputId": "1f27bebd-ecda-4fda-f9f9-fe9b7f33278b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>sign</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>130144</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5080</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841367</th>\n",
              "      <td>92808</td>\n",
              "      <td>131814</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841368</th>\n",
              "      <td>131816</td>\n",
              "      <td>131817</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841369</th>\n",
              "      <td>131819</td>\n",
              "      <td>131820</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841370</th>\n",
              "      <td>131824</td>\n",
              "      <td>131825</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841371</th>\n",
              "      <td>131826</td>\n",
              "      <td>131827</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>841372 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        source  target  sign\n",
              "0            1       2    -1\n",
              "1       130144       2     1\n",
              "2         5080       3     1\n",
              "3            3       4     1\n",
              "4          117       4     1\n",
              "...        ...     ...   ...\n",
              "841367   92808  131814    -1\n",
              "841368  131816  131817     1\n",
              "841369  131819  131820    -1\n",
              "841370  131824  131825     1\n",
              "841371  131826  131827     1\n",
              "\n",
              "[841372 rows x 3 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "73e49f09",
      "metadata": {
        "id": "73e49f09"
      },
      "outputs": [],
      "source": [
        "df_no_dup = df_raw.drop_duplicates(inplace = False)\n",
        "df_no_dup = df_no_dup.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "44d62bca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "44d62bca",
        "outputId": "3e6681d3-b178-415b-b00c-dab5f794223f",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>sign</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>130144</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5080</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841367</th>\n",
              "      <td>92808</td>\n",
              "      <td>131814</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841368</th>\n",
              "      <td>131816</td>\n",
              "      <td>131817</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841369</th>\n",
              "      <td>131819</td>\n",
              "      <td>131820</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841370</th>\n",
              "      <td>131824</td>\n",
              "      <td>131825</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841371</th>\n",
              "      <td>131826</td>\n",
              "      <td>131827</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>841372 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        source  target  sign\n",
              "0            1       2    -1\n",
              "1       130144       2     1\n",
              "2         5080       3     1\n",
              "3            3       4     1\n",
              "4          117       4     1\n",
              "...        ...     ...   ...\n",
              "841367   92808  131814    -1\n",
              "841368  131816  131817     1\n",
              "841369  131819  131820    -1\n",
              "841370  131824  131825     1\n",
              "841371  131826  131827     1\n",
              "\n",
              "[841372 rows x 3 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_no_dup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "05691ab6",
      "metadata": {
        "id": "05691ab6"
      },
      "outputs": [],
      "source": [
        "# function to assign new ids to nodes regarding keeping ids in zero to num_of_nodes - 1\n",
        "def relabel(df):\n",
        "    source_old_labels = df[\"source\"].drop_duplicates().to_numpy()\n",
        "    #print(source_old_labels)\n",
        "    target_old_labels = df[\"target\"].drop_duplicates().to_numpy()\n",
        "    all_old_labels = np.union1d(source_old_labels, target_old_labels)\n",
        "    index_map = dict(enumerate(all_old_labels))\n",
        "    new_index_map = dict([(value, key) for key, value in index_map.items()])\n",
        "    #print(index_map == new_index_map)\n",
        "    new_df = df.copy()\n",
        "    for index, row in new_df.iterrows():\n",
        "        #print(row[\"source\"])\n",
        "        row[\"source\"] = new_index_map[row[\"source\"]]\n",
        "        row[\"target\"] = new_index_map[row[\"target\"]]\n",
        "    return new_index_map, new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "12f8a5fc",
      "metadata": {
        "id": "12f8a5fc"
      },
      "outputs": [],
      "source": [
        "ind_map, df_relabled = relabel(df_no_dup)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9ca26b10",
      "metadata": {
        "id": "9ca26b10"
      },
      "source": [
        "#### اگر طوقه داشته باشه دیتاست نباید از MultiDiGraph استفاده شود"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b69d8601",
      "metadata": {
        "id": "b69d8601"
      },
      "outputs": [],
      "source": [
        "main_graph = nx.DiGraph()\n",
        "main_graph = nx.from_pandas_edgelist(df = df_relabled, source = 'source', target = 'target', edge_attr = 'sign', create_using = nx.DiGraph(), edge_key = 'sign')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5dc371ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dc371ca",
        "outputId": "df661c51-0c22-4ced-93ec-7ffdf6c262da",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of nodes G = 131828\n",
            "number of edges G = 841372\n",
            "Density of G: 4.841456374018419e-05\n"
          ]
        }
      ],
      "source": [
        "print('number of nodes G =', nx.number_of_nodes(main_graph) )\n",
        "print('number of edges G =', nx.number_of_edges(main_graph) )\n",
        "print('Density of G:', nx.density(main_graph))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "293c1bc7",
      "metadata": {
        "id": "293c1bc7"
      },
      "source": [
        "### توجه شود که اختلاف تعداد یال‎های گراف با سطرهای دیتافریم به دلیل وجود یال چندگانه یا طوقه در دیتا فریم است."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "918de99e",
      "metadata": {
        "id": "918de99e"
      },
      "outputs": [],
      "source": [
        "def graphTrainTestSplit(G, df, train_size, positive_size = 0.8):\n",
        "    G_train = G.copy()\n",
        "    train_df = df.copy()\n",
        "    test_df = df.copy()\n",
        "    edges_no = nx.number_of_edges(G_train)\n",
        "    test_size = 1 - train_size\n",
        "    \n",
        "    # Get the indices of positive and negative labels\n",
        "    positive_indices = train_df[train_df['sign'] == 1].index.to_list()\n",
        "    negative_indices = train_df[train_df['sign'] == -1].index.to_list()\n",
        "    \n",
        "    # Shuffle the indices randomly\n",
        "    random.shuffle(positive_indices)\n",
        "    random.shuffle(negative_indices)\n",
        "    \n",
        "    # Calculate the number of positive and negative labels for test set\n",
        "    negative_size = 1 - positive_size\n",
        "    test_positive_count = int(test_size * edges_no * positive_size)\n",
        "    test_negative_count = int(test_size * edges_no * negative_size)\n",
        "    # test_positive_count = int(train_size * len(positive_indices))\n",
        "    # test_negative_count = int(train_size * len(negative_indices))\n",
        "    number_of_edges_left_for_removal = test_positive_count + test_negative_count\n",
        "    \n",
        "    edges_to_remove = []  # List to store edges for removal\n",
        "    \n",
        "    #print(\"number_of_edges_left_for_removal: \", number_of_edges_left_for_removal, 'test_positive_count:', test_positive_count, 'test_negative_count: ', test_negative_count)\n",
        "\n",
        "    while number_of_edges_left_for_removal > 0:\n",
        "        edges = np.array(G_train.edges)\n",
        "        chosen_edge = random.choice(edges)\n",
        "        source = chosen_edge[0]\n",
        "        target = chosen_edge[1]\n",
        "        \n",
        "        if (G_train.degree[source] > 1 and G_train.degree[target] > 1):\n",
        "            label = train_df.loc[(train_df['source'] == source) & (train_df['target'] == target), 'sign'].values[0]\n",
        "            \n",
        "            # Check if the edge label matches the desired distribution\n",
        "            if (label == 1 and test_positive_count > 0) or (label == -1 and test_negative_count > 0):\n",
        "                if G_train.has_edge(source, target):\n",
        "                    edges_to_remove.append((source, target))\n",
        "                    G_train.remove_edge(source, target)\n",
        "                    if label == 1:\n",
        "                        test_positive_count -= 1\n",
        "                    else:\n",
        "                        test_negative_count -= 1\n",
        "                    number_of_edges_left_for_removal -= 1\n",
        "\n",
        "    #print('edges_to_remove size: ', len(edges_to_remove))    \n",
        "    # Remove the corresponding rows from the train DataFrame\n",
        "    # train_df = train_df.drop(train_df[(train_df['source'].isin([edge[0] for edge in edges_to_remove])) &  (train_df['target'].isin([edge[1] for edge in edges_to_remove]))].index)\n",
        "    \n",
        "    mask = train_df[['source', 'target']].apply(tuple, axis=1).isin(edges_to_remove)\n",
        "    train_df = train_df[~mask]\n",
        "\n",
        "    test_df = test_df.merge(train_df, how='left', indicator=True)\n",
        "    test_df = test_df[test_df['_merge'] == 'left_only'].drop('_merge', axis=1)\n",
        "    \n",
        "    return G_train, train_df, test_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5b9500d3",
      "metadata": {
        "id": "5b9500d3"
      },
      "outputs": [],
      "source": [
        "# def graphTrainTestSplit(G, df, train_size):\n",
        "#     G_train = G.copy()\n",
        "#     train_df = df.copy()\n",
        "#     test_df = df.copy()\n",
        "#     edges_no = nx.number_of_edges(G_train)\n",
        "#     number_of_edges_left_for_removal = np.floor((1 - train_size) * edges_no)\n",
        "#     while (number_of_edges_left_for_removal > 0):\n",
        "#         edges = np.array(G_train.edges)\n",
        "#         chosen_edge = random.choice(edges)\n",
        "#         if (G_train.degree[chosen_edge[0]] > 1 and G_train.degree[chosen_edge[1]] > 1):\n",
        "#             G_train.remove_edge(chosen_edge[0], chosen_edge[1])\n",
        "            \n",
        "#             # Get indexes where name column has value\n",
        "#             index_names = train_df.index[(train_df['source'] == chosen_edge[0]) & (train_df['target'] == chosen_edge[1])]\n",
        "#             # Delete these row indexes from dataFrame\n",
        "#             train_df.drop(index_names, inplace = True)\n",
        "            \n",
        "#             number_of_edges_left_for_removal -= 1\n",
        "#     test_df = test_df.merge(train_df, how='left', indicator=True)\n",
        "#     test_df = test_df[test_df['_merge'] == 'left_only'].drop('_merge', axis=1)\n",
        "#     return G_train, train_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7499a852",
      "metadata": {
        "id": "7499a852"
      },
      "outputs": [],
      "source": [
        "train_graph, train_df, test_df = graphTrainTestSplit(main_graph, df_relabled, 0.99987163838155015670814252418369)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c11781e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to add negative and positive weight columns to the dataframe\n",
        "\n",
        "def labelPosWeight (row):\n",
        "   if row['sign'] == 1 :\n",
        "      return 1\n",
        "   else:\n",
        "      return 0\n",
        "\n",
        "def labelNegWeight (row):\n",
        "   if row['sign'] == -1 :\n",
        "      return 1\n",
        "   else:\n",
        "      return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1c4a2a7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df['pos_weight'] = train_df.apply (lambda row: labelPosWeight(row), axis=1)\n",
        "train_df['neg_weight'] = train_df.apply (lambda row: labelNegWeight(row), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "cbd9d5e3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>sign</th>\n",
              "      <th>pos_weight</th>\n",
              "      <th>neg_weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>130143</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5079</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>116</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841367</th>\n",
              "      <td>92807</td>\n",
              "      <td>131813</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841368</th>\n",
              "      <td>131815</td>\n",
              "      <td>131816</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841369</th>\n",
              "      <td>131818</td>\n",
              "      <td>131819</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841370</th>\n",
              "      <td>131823</td>\n",
              "      <td>131824</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841371</th>\n",
              "      <td>131825</td>\n",
              "      <td>131826</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>841265 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        source  target  sign  pos_weight  neg_weight\n",
              "0            0       1    -1           0           1\n",
              "1       130143       1     1           1           0\n",
              "2         5079       2     1           1           0\n",
              "3            2       3     1           1           0\n",
              "4          116       3     1           1           0\n",
              "...        ...     ...   ...         ...         ...\n",
              "841367   92807  131813    -1           0           1\n",
              "841368  131815  131816     1           1           0\n",
              "841369  131818  131819    -1           0           1\n",
              "841370  131823  131824     1           1           0\n",
              "841371  131825  131826     1           1           0\n",
              "\n",
              "[841265 rows x 5 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "32b41324",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of nodes G = 131828\n",
            "number of edges G = 841265\n",
            "Density of G: 4.8408406703439204e-05\n"
          ]
        }
      ],
      "source": [
        "print('number of nodes G =', nx.number_of_nodes(train_graph) )\n",
        "print('number of edges G =', nx.number_of_edges(train_graph) )\n",
        "print('Density of G:', nx.density(train_graph))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6cf390ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "def linePrepender(filename, line):\n",
        "    with open(filename, 'r+') as f:\n",
        "        content = f.read()\n",
        "        f.seek(0, 0)\n",
        "        f.write(line.rstrip('\\r\\n') + '\\n' + content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ca0e730f",
      "metadata": {},
      "outputs": [],
      "source": [
        "soc_df = train_df[['source', 'target', 'pos_weight', 'neg_weight']]\n",
        "soc_df.to_csv(\"Datasets\\soc.tsv\", index = False, header = False, sep = '\\t')\n",
        "linePrepender(\"Datasets\\soc.tsv\", str(nx.number_of_nodes(train_graph)) + '\\t' + str(nx.number_of_edges(train_graph)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OkWA6V5GO91U",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkWA6V5GO91U",
        "outputId": "37d36c97-36ac-4f5c-c806-24709ebab8ec"
      },
      "outputs": [],
      "source": [
        "num_duplicates = test_df.duplicated().sum()\n",
        "print(\"Number of duplicates:\", num_duplicates)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "451b9c43",
      "metadata": {
        "id": "451b9c43"
      },
      "outputs": [],
      "source": [
        "rows = train_df.loc[:, \"source\"].to_numpy()\n",
        "cols = train_df.loc[:, \"target\"].to_numpy()\n",
        "sign = train_df.loc[:, \"sign\"].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ec1c649",
      "metadata": {
        "id": "3ec1c649"
      },
      "outputs": [],
      "source": [
        "p_rows = [rows[i] for i in range(len(rows)) if sign[i] == 1]\n",
        "p_cols = [cols[i] for i in range(len(cols)) if sign[i] == 1]\n",
        "p_data = np.ones(len(p_rows))\n",
        "\n",
        "n_rows = [rows[i] for i in range(len(rows)) if sign[i] == -1]\n",
        "n_cols = [cols[i] for i in range(len(cols)) if sign[i] == -1]\n",
        "n_data = np.ones(len(n_rows))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a53631fe",
      "metadata": {
        "id": "a53631fe"
      },
      "outputs": [],
      "source": [
        "nodes_no = nx.number_of_nodes(train_graph)\n",
        "edges_no = nx.number_of_edges(train_graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18644208",
      "metadata": {
        "id": "18644208",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "A_p = sc.sparse.csc_matrix((p_data, (p_rows, p_cols)), shape = (nodes_no , nodes_no))\n",
        "A_n = sc.sparse.csc_matrix((n_data, (n_rows, n_cols)), shape = (nodes_no , nodes_no))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a961ac9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a961ac9",
        "outputId": "a029a1ef-8843-4881-a4eb-8c4bf792e384"
      },
      "outputs": [],
      "source": [
        "print(p_data.shape)\n",
        "print(n_data.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "0e56cf49",
      "metadata": {
        "id": "0e56cf49"
      },
      "source": [
        "# اینجاااااااااااااااااااااااااااااااااااااااااااااااااااااا"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3603fa90",
      "metadata": {
        "id": "3603fa90"
      },
      "outputs": [],
      "source": [
        "def getNeighborsOfANode(graph, node):\n",
        "    x = []\n",
        "    for v in graph.nodes():\n",
        "        if ((v, node) in graph.edges()):\n",
        "            x.append(v)\n",
        "    return np.array(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d60c6603",
      "metadata": {
        "id": "d60c6603"
      },
      "outputs": [],
      "source": [
        "# def NodeswithoutInAndOutneighbors(G, sign_tag = 'sign'):\n",
        "#     nodes_no = nx.number_of_nodes(G)\n",
        "#     sign_map = nx.get_edge_attributes(G, sign_tag)\n",
        "#     n = 0\n",
        "#     for u in G.nodes():\n",
        "#         for v in G.nodes():\n",
        "#             #print(\"u: \", u, \", v: \", v)\n",
        "#             if (u != v):\n",
        "#                 u_neighbors = set(G.adj[u])\n",
        "#                 v_neighbors = set(G.adj[v])\n",
        "#                 uv_neighbors = list(u_neighbors.intersection(v_neighbors))\n",
        "#                 u_inneighbors = set(getNeighborsOfANode(G, u))\n",
        "#                 v_inneighbors = set(getNeighborsOfANode(G, v))\n",
        "#                 uv_inneighbors = list(u_inneighbors.intersection(v_inneighbors))\n",
        "#                 if (len(uv_neighbors) + len(uv_inneighbors)) == 0 and (u,v) in G.edges():\n",
        "#                     n = n+1\n",
        "#                     print(\"(u,v):\" , (u,v))\n",
        "#     return n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "8f6898d1",
      "metadata": {
        "id": "8f6898d1"
      },
      "outputs": [],
      "source": [
        "#c = Cluster((A_p, A_n))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "6e7b7ea4",
      "metadata": {
        "id": "6e7b7ea4"
      },
      "outputs": [],
      "source": [
        "def getClusters(G, k, A_p, A_n):\n",
        "    c = Cluster((A_p, A_n))\n",
        "    #spec_clus = c.spectral_cluster_adjacency(k = 5, normalisation = 'sym_sep', eigens = None, mi = None)\n",
        "    spec_clus = c.spectral_cluster_bnc(k = 5, normalisation='sym', eigens=None, mi=None)\n",
        "    clusters = []\n",
        "    for j in range(k):\n",
        "        clusters.append([i for i in G.nodes() if spec_clus[int(i - 1)] == j])\n",
        "    return np.array(clusters, dtype = np.ndarray)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "e91a18ea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------\n",
            "Loading dataset 'Datasets\\soc.tsv'...\n",
            "Dataset successfully loaded in 3676 ms\n",
            "#vertices: 131828\n",
            "#edges: 841265\n",
            "#vertex pairs: 8689244878\n",
            "#vertex triples: 381822798429076\n",
            "Global condition (without tot_min): 8.18405983471007e-05 >= 1.0 ?\n",
            "Global condition (including tot_min): 8.18405983471007e-05 >= 1.0 ?\n",
            "Solver: pulp\n",
            "---------------\n",
            "CC cost of 'whole graph in one cluster' solution: 120727.0 (tot_min: 0.0, cost-tot_min: 120727.0)\n",
            "CC cost of 'all singletons' solution: 590406.0 (tot_min: 0.0, cost-tot_min: 590406.0)\n",
            "---------------\n",
            "Running KwikCluster algorithm...\n",
            "KwikCluster algorithm successfully executed in 312 ms\n",
            "CC cost of KwikCluster's output clustering: 513070.0 (tot_min: 0.0, cost-tot_min: 513070.0)\n",
            "KwikCluster's output clustering:\n",
            "Cluster 1: [122893, 122894]\n",
            "---------------\n",
            "O(log n)-approximation algorithm - Building linear program (solver: pulp)...\n"
          ]
        },
        {
          "ename": "MemoryError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-22-be94b15846f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'O(log n)-approximation algorithm - Building linear program (solver: %s)...'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m                 \u001b[0mid2vertexpair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vertex_pair_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Alireza\\Desktop\\Programming\\Link-Prediction\\pyccalg.py\u001b[0m in \u001b[0;36m_vertex_pair_ids\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m                         \u001b[0mid2vertexpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m                         \u001b[0mid\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mid2vertexpair\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mMemoryError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#if __name__ == '__main__':\n",
        "#read parameters\n",
        "#(dataset_file,random_edgeweight_generation,edge_addition_prob,solver,algorithm) = _read_params()\n",
        "(dataset_file,random_edgeweight_generation,edge_addition_prob,solver,algorithm) = (\"Datasets\\soc.tsv\", None, -1, 'pulp', 'demaine')\n",
        "\n",
        "#load dataset\n",
        "print(separator)\n",
        "print('Loading dataset \\'%s\\'...' %(dataset_file))\n",
        "start = time.time()\n",
        "(id2vertex,vertex2id,edges,graph,tot_min) = ca._load(dataset_file,random_edgeweight_generation,edge_addition_prob)\n",
        "runtime = ca._running_time_ms(start)\n",
        "n = len(id2vertex)\n",
        "m = len(edges)\n",
        "vertex_pairs = n*(n-1)/2\n",
        "vertex_triples = n*(n-1)*(n-2)/6\n",
        "print('Dataset successfully loaded in %d ms' %(runtime))\n",
        "print('#vertices: %d' %(n))\n",
        "print('#edges: %d' %(m))\n",
        "print('#vertex pairs: %d' %(vertex_pairs))\n",
        "print('#vertex triples: %d' %(vertex_triples))\n",
        "if random_edgeweight_generation:\n",
        "\tprint('Edge weights randomly generated from [%s,%s]' %(random_edgeweight_generation[0],random_edgeweight_generation[1]))\n",
        "\tif edge_addition_prob > 0:\n",
        "\t\tprint('Edge-addition probability: %s' %(edge_addition_prob))\n",
        "all_edgeweights_sum = ca._all_edgeweights_sum(graph)\n",
        "max_edgeweight_gap = ca._max_edgeweight_gap(graph)\n",
        "print('Global condition (without tot_min): %s >= %s ?' %(all_edgeweights_sum/vertex_pairs,max_edgeweight_gap))\n",
        "print('Global condition (including tot_min): %s >= %s ?' %((all_edgeweights_sum+tot_min)/vertex_pairs,max_edgeweight_gap))\n",
        "print('Solver: %s' %(solver))\n",
        "\n",
        "#baseline CC costs\n",
        "print(separator)\n",
        "singlecluster_cost = ca._CC_cost([set(id2vertex.keys())],graph) + tot_min\n",
        "allsingletons_cost = ca._CC_cost([{u} for u in id2vertex.keys()],graph) + tot_min\n",
        "print('CC cost of \\'whole graph in one cluster\\' solution: %s (tot_min: %s, cost-tot_min: %s)' %(singlecluster_cost,tot_min,singlecluster_cost-tot_min))\n",
        "print('CC cost of \\'all singletons\\' solution: %s (tot_min: %s, cost-tot_min: %s)' %(allsingletons_cost,tot_min,allsingletons_cost-tot_min))\n",
        "\n",
        "#run KwikCluster algorithm (to have some baseline results)\n",
        "print(separator)\n",
        "print('Running KwikCluster algorithm...')\n",
        "start = time.time()\n",
        "kc_clustering = kwikcluster(id2vertex,graph)\n",
        "runtime = ca._running_time_ms(start)\n",
        "check_clustering = ca._check_clustering(kc_clustering,n)\n",
        "if not check_clustering:\n",
        "\traise Exception('ERROR: malformed clustering')\n",
        "print('KwikCluster algorithm successfully executed in %d ms' %(runtime))\n",
        "kc_cost = ca._CC_cost(kc_clustering,graph) + tot_min\n",
        "print('CC cost of KwikCluster\\'s output clustering: %s (tot_min: %s, cost-tot_min: %s)' %(kc_cost,tot_min,kc_cost-tot_min))\n",
        "print('KwikCluster\\'s output clustering:')\n",
        "c = 1\n",
        "for cluster in kc_clustering:\n",
        "\tmapped_cluster = ca._map_cluster(cluster,id2vertex)\n",
        "\tprint('Cluster ' + str(c) + ': ' + str(sorted(mapped_cluster)))\n",
        "\tc += 1\n",
        "\n",
        "\tif algorithm == 'charikar' or algorithm == 'demaine':\n",
        "\t\t#build linear program\n",
        "\t\tprint(separator)\n",
        "\t\tprint('O(log n)-approximation algorithm - Building linear program (solver: %s)...' %(solver))\n",
        "\t\tstart = time.time()\n",
        "\t\tid2vertexpair = ca._vertex_pair_ids(n)\n",
        "\t\tmodel = None\n",
        "\t\tA = None\n",
        "\t\tb = None\n",
        "\t\tc = None\n",
        "\t\tc_nonzero = None\n",
        "\t\tif solver == 'pulp':\n",
        "\t\t\tmodel = ca._linear_program_pulp(n,edges,graph)\n",
        "\t\telif solver == 'scipy':\n",
        "\t\t\t(A,b,c) = ca._linear_program_scipy(n,edges,graph)\n",
        "\t\t\tc_nonzero = len([x for x in c if x != 0])\n",
        "\t\telse:\n",
        "\t\t\traise Exception('Solver \\'%s\\' not supported' %(solver))\n",
        "\t\truntime = ca._running_time_ms(start)\n",
        "\t\tprint('Linear program successfully built in %d ms' %(runtime))\n",
        "\t\tif solver == 'scipy':\n",
        "\t\t\tprint('#variables: %d (must be equal to #vertex pairs, i.e., equal to %d)' %(len(c),vertex_pairs))\n",
        "\t\t\tprint('#inequality constraints: %d (must be equal to 3 * #vertex triples, i.e., equal to %d)' %(len(A),3*vertex_triples))\n",
        "\t\t\tprint('#non-zero entries in cost vector: %d (must be <= #edges, i.e., <= %d)' %(c_nonzero,m))\n",
        "\n",
        "\t\t#solving linear program\n",
        "\t\tprint(separator)\n",
        "\t\tprint('O(log n)-approximation algorithm - Solving linear program (solver: %s)...' %(solver))\n",
        "\t\tstart=time.time()\n",
        "\t\tlp_var_assignment = None\n",
        "\t\tobj_value = None\n",
        "\t\tmethod = ''\n",
        "\t\tif solver == 'pulp':\n",
        "\t\t\tmethod = 'PuLP'\n",
        "\t\t\t(lp_var_assignment,obj_value) = ca._solve_lp_pulp(model)\n",
        "\t\telif solver == 'scipy':\n",
        "\t\t\tmethod = 'SciPy'\n",
        "\t\t\t(lp_var_assignment,obj_value) = ca._solve_lp_scipy(A,b,c)\n",
        "\t\telse:\n",
        "\t\t\traise Exception('Solver \\'%s\\' not supported' %(solver))\n",
        "\t\truntime = ca._running_time_ms(start)\n",
        "\t\tlp_cost = ca._lp_solution_cost(lp_var_assignment,graph,n) + tot_min\n",
        "\t\tprint('Linear program successfully solved in %d ms' %(runtime))\n",
        "\t\tprint('Size of the solution array: %d (must be equal to #variables)' %(len(lp_var_assignment)))\n",
        "\t\tprint('Cost of the LP solution: %s (tot_min: %s, cost-tot_min: %s)' %(lp_cost,tot_min,lp_cost-tot_min))\n",
        "\t\tall_negativeedgeweight_sum = ca._all_negativeedgeweight_sum(graph)\n",
        "\t\tprint('Cost of the LP solution (according to %s): %s (tot_min: %s, cost-tot_min: %s)' %(method,obj_value+all_negativeedgeweight_sum+tot_min,tot_min,obj_value+all_negativeedgeweight_sum))\n",
        "\t\t# \"\"\"\n",
        "\t\t# #######################\n",
        "\t\t# #######################\n",
        "\t\t# #######################\n",
        "\t\t# ## DEBUG:\n",
        "\t\t# if solver == 'pulp':\n",
        "\t\t# \t(A,b,c) = _linear_program_scipy(n,edges,graph)\n",
        "\t\t# \t(lp_var_assignment_scipy,obj_value_scipy) = _solve_lp_scipy(A,b,c)\n",
        "\t\t# \tlp_cost_scipy = _lp_solution_cost(lp_var_assignment_scipy,graph,n) + tot_min\n",
        "\t\t# \tprint('Cost of the SciPy LP solution: %s (tot_min: %s)' %(lp_cost_scipy,tot_min))\n",
        "\t\t# \tprint('Cost of the SciPy LP solution (according to SciPy): %s (tot_min: %s)' %(obj_value_scipy+all_negativeedgeweight_sum+tot_min,tot_min))\n",
        "\t\t# \tfor i in range(len(lp_var_assignment)):\n",
        "\t\t# \t\tscipy_val = lp_var_assignment_scipy[i]\n",
        "\t\t# \t\tpulp_val = lp_var_assignment[i]\n",
        "\t\t# \t\tdiff = abs(scipy_val-pulp_val)\n",
        "\t\t# \t\tpedix = '(difference: ' + str(diff) + ')' if diff>0 else ''\n",
        "\t\t# \t\tprint('x_%d (SciPy, PuLP): %s %s %s' %(i,scipy_val,pulp_val,pedix))\n",
        "\t\t# else:\n",
        "\t\t# \tprint(lp_var_assignment)\n",
        "\t\t# #######################\n",
        "\t\t# #######################\n",
        "\t\t# #######################\n",
        "\t\t# \"\"\"\n",
        "\n",
        "\t\t#rounding lp solution\n",
        "\t\tprint(separator)\n",
        "\t\tprint('O(log n)-approximation algorithm - Rounding the LP solution (rounding algorithm: %s)...' %(algorithm))\n",
        "\t\tstart=time.time()\n",
        "\t\tclustering = None\n",
        "\t\tif algorithm == 'charikar':\n",
        "\t\t\tclustering = round_charikar(lp_var_assignment,id2vertexpair,id2vertex,edges,graph,lp_cost-tot_min)\n",
        "\t\telif algorithm == 'demaine':\n",
        "\t\t\tclustering = round_demaine(lp_var_assignment,id2vertexpair,id2vertex,edges,graph,2+eps)\n",
        "\t\truntime = ca._running_time_ms(start)\n",
        "\t\tcheck_clustering = ca._check_clustering(clustering,n)\n",
        "\t\tif not check_clustering:\n",
        "\t\t\traise Exception('ERROR: malformed clustering')\n",
        "\t\tprint('LP-rounding successfully performed in %d ms' %(runtime))\n",
        "\t\tcc_cost = ca._CC_cost(clustering,graph) + tot_min\n",
        "\t\tprint('CC cost of O(log n)-approximation algorithm\\'s output clustering: %s (tot_min: %s, cost-tot_min: %s)' %(cc_cost,tot_min,cc_cost-tot_min))\n",
        "\t\tprint('O(log n)-approximation algorithm\\'s output clustering:')\n",
        "\t\tc = 1\n",
        "\t\tfor cluster in clustering:\n",
        "\t\t\tmapped_cluster = ca._map_cluster(cluster,id2vertex)\n",
        "\t\t\tprint('Cluster ' + str(c) + ': ' + str(sorted(mapped_cluster)))\n",
        "\t\t\tc += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7da5dbc3",
      "metadata": {},
      "outputs": [],
      "source": [
        "kc_clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec446168",
      "metadata": {},
      "outputs": [],
      "source": [
        "#demaine\n",
        "clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8c331dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8c331dd",
        "outputId": "6205da18-5b6e-4892-b59d-9e5683ea52d7"
      },
      "outputs": [],
      "source": [
        "#main_clusters = getClusters(train_graph, 5, A_p, A_n)\n",
        "main_clusters = np.array(kc_clustering, dtype = np.ndarray)\n",
        "cluster1 = main_clusters[0]\n",
        "cluster2 = main_clusters[1]\n",
        "cluster3 = main_clusters[2]\n",
        "cluster4 = main_clusters[3]\n",
        "cluster5 = main_clusters[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e3f0631",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e3f0631",
        "outputId": "85f99509-ee56-4304-95c4-fc26c6d3c228"
      },
      "outputs": [],
      "source": [
        "print(len(cluster1))\n",
        "print(len(cluster2))\n",
        "print(len(cluster3))\n",
        "print(len(cluster4))\n",
        "print(len(cluster5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a74788dc",
      "metadata": {
        "id": "a74788dc"
      },
      "outputs": [],
      "source": [
        "def getCommonNeighbors(G, cl1, cl2):\n",
        "    x = set([])\n",
        "    for i in cl1:\n",
        "        x = x.union(set(G.adj[i]))\n",
        "    #print('x: ', x)\n",
        "    y = set([])\n",
        "    for j in cl2:\n",
        "        y = y.union(set(G.adj[j]))\n",
        "    #print('y: ', y)\n",
        "    return list(x.intersection(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "031c1e03",
      "metadata": {
        "id": "031c1e03"
      },
      "outputs": [],
      "source": [
        "def locationOfANode(clusters, u):\n",
        "    n = clusters.shape[0]\n",
        "    x = np.zeros(n)\n",
        "    r = -1\n",
        "    for i in range(n):\n",
        "        if u in clusters[i]:\n",
        "            r = i\n",
        "    return r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "165dfc34",
      "metadata": {
        "id": "165dfc34"
      },
      "outputs": [],
      "source": [
        "\n",
        "def locationOfArrayOfNode(clusters, U):\n",
        "    x = np.zeros(len(U))\n",
        "    for i in range(len(x)):\n",
        "        x[i] = locationOfANode(clusters, U[i])\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ee81b85",
      "metadata": {
        "id": "8ee81b85"
      },
      "outputs": [],
      "source": [
        "def getClusterSimiliarity(G, source_cluster, common_neighbors, sign_tag = 'sign'):\n",
        "    #print('common_neighbors: ', common_neighbors)\n",
        "    sign_map = nx.get_edge_attributes(G, sign_tag)\n",
        "    epsilon = 10 ** (-5)\n",
        "    y = []\n",
        "    for v in common_neighbors:\n",
        "        # adding an epsilon to prevent mean of an empty array\n",
        "        #x = [epsilon]\n",
        "        x = []\n",
        "        for u in source_cluster:\n",
        "            if (u, v) in G.edges():\n",
        "                x.append(sign_map[(u, v)])\n",
        "                #print(\"u\", u , \"v\" , v)\n",
        "        y.append(np.mean(np.array(x)))\n",
        "    return np.array(y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "60ec2a0e",
      "metadata": {
        "id": "60ec2a0e"
      },
      "source": [
        "##################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06c614c8",
      "metadata": {
        "id": "06c614c8"
      },
      "outputs": [],
      "source": [
        "# main function to calculate the similiarity between two clusters\n",
        "def getInterClusterSimiliarity(G, cl1, cl2, common_neighbors):\n",
        "   y1 = getClusterSimiliarity(G, cl1, common_neighbors)\n",
        "   y2 = getClusterSimiliarity(G, cl2, common_neighbors)\n",
        "   \n",
        "   # if (y1.size == 0):\n",
        "   #    print('y1: ', y1)\n",
        "   #    print('###', common_neighbors)\n",
        "   # if (y2.size == 0):\n",
        "   #    print('y2: ', y2)\n",
        "   #    print('###', common_neighbors)\n",
        "\n",
        "   alpha = np.dot(y1.T, y2)\n",
        "\n",
        "   ##first approach\n",
        "   beta = np.dot(y1.T, y1)\n",
        "   gamma = np.dot(y2.T, y2)\n",
        "   if (beta * gamma < 0):\n",
        "      print('it\"s negative: ', beta * gamma)\n",
        "   epsilon = 10 ** (-5)\n",
        "   #return alpha / (np.sqrt((beta * gamma)) + epsilon)\n",
        "   return alpha / (np.sqrt((beta * gamma)))\n",
        "\n",
        "   ##second approach\n",
        "   #return alpha / len(common_neighbors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bee73e85",
      "metadata": {
        "id": "bee73e85"
      },
      "outputs": [],
      "source": [
        "# # calculates similiarities between each two clusters and returns a matrix\n",
        "# def getAllSimiliaritiesBetweenClusters(G, clusters):\n",
        "#     clusters_no = clusters.shape[0]\n",
        "#     similiarities = np.zeros(shape = (clusters_no, clusters_no))\n",
        "#     for i in range(clusters_no):\n",
        "#         for j in range(i, clusters_no):\n",
        "#             common_neighbors = getCommonNeighbors(G, clusters[i], clusters[j])\n",
        "#             current_similiarity = getInterClusterSimiliarity(G, clusters[i], clusters[j], common_neighbors)\n",
        "#             # similiarities[i][j] = similiarities[j][i] = current_similiarity\n",
        "#             if len(common_neighbors) == 0:\n",
        "#                 print('i:', clusters[i])\n",
        "#                 print('j:', clusters[j])\n",
        "#             if (math.isnan(current_similiarity)):\n",
        "#                 similiarities[i][j] = similiarities[j][i] = 0\n",
        "#             else:\n",
        "#                 similiarities[i][j] = similiarities[j][i] = current_similiarity\n",
        "#     return similiarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e880f85a",
      "metadata": {
        "id": "e880f85a"
      },
      "outputs": [],
      "source": [
        "# Calculates similarities between each two clusters and returns a matrix\n",
        "def getAllSimilaritiesBetweenClusters(G, clusters):\n",
        "    clusters_no = clusters.shape[0]\n",
        "    similiarities = np.zeros(shape=(clusters_no, clusters_no), dtype = 'float16')\n",
        "    total_iterations = clusters_no * (clusters_no + 1) // 2  # Total number of iterations for progress bar\n",
        "\n",
        "    with tqdm(total=total_iterations, desc=\"Calculating similarities\") as pbar:\n",
        "        for i in range(clusters_no):\n",
        "            for j in range(i, clusters_no):\n",
        "                if i == j:\n",
        "                    similiarities[i][j] = 1\n",
        "                else:\n",
        "                    common_neighbors = getCommonNeighbors(G, clusters[i], clusters[j])\n",
        "                    current_similarity = getInterClusterSimiliarity(G, clusters[i], clusters[j], common_neighbors)\n",
        "\n",
        "                    if len(common_neighbors) == 0:\n",
        "                        print('i:', clusters[i])\n",
        "                        print('j:', clusters[j])\n",
        "                    if math.isnan(current_similarity):\n",
        "                        similiarities[i][j] = similiarities[j][i] = 0\n",
        "                    else:\n",
        "                        similiarities[i][j] = similiarities[j][i] = current_similarity\n",
        "\n",
        "                pbar.update(1)  # Update the progress bar\n",
        "\n",
        "    return similiarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "192ae994",
      "metadata": {
        "id": "192ae994"
      },
      "outputs": [],
      "source": [
        "# common_neighbors = getCommonNeighbors(train_graph, cluster1, cluster2)\n",
        "# similarity = getInterClusterSimiliarity(train_graph, cluster1, cluster2, common_neighbors)\n",
        "# similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e377cba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e377cba",
        "outputId": "a31b142b-c990-4960-cff0-524fef1dd27b"
      },
      "outputs": [],
      "source": [
        "matrix_of_similarity = getAllSimilaritiesBetweenClusters(train_graph, main_clusters)\n",
        "matrix_of_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cb4e156",
      "metadata": {
        "id": "0cb4e156"
      },
      "outputs": [],
      "source": [
        "def signPrediction(G, main_clusters, all_similiarities, k, u, v, threshold, w1, sign_tag = \"sign\"):\n",
        "    sign_map = nx.get_edge_attributes(G, sign_tag)\n",
        "    #main_clusters = getClusters(G, k)\n",
        "    \n",
        "    u_c = locationOfANode(main_clusters, u)\n",
        "    u_v = locationOfANode(main_clusters, v)\n",
        "    cl1 = main_clusters[u_c]\n",
        "    cl2 = main_clusters[u_v]\n",
        "    #s_AB = getCommonNeighbors(G, cl1, cl2)\n",
        "    #print(s_AB)\n",
        "    S = getNeighborsOfANode(G, v)\n",
        "    S_c = locationOfArrayOfNode(main_clusters, S)\n",
        "    n = len(S)\n",
        "    x = np.zeros(n)\n",
        "    for i in range(n):\n",
        "        #x[i] = getInterClusterSimiliarity(main_clusters[u_c], main_clusters[int(S_c[i])], s_AB)\n",
        "        x[i] = all_similiarities[u_c][int(S_c[i])]\n",
        "        #print('main_clusters_u_c: ', main_clusters[u_c])\n",
        "        #print('main_clusters_int: ', main_clusters[int(S_c[i])])\n",
        "        #print('s_AB: ', s_AB)\n",
        "        #print('x[i]' , x[i]  )\n",
        "        \n",
        "        # if locationOfANode(main_clusters, u) == locationOfANode(main_clusters, S_c[i]):\n",
        "        #     x[i] = w1 * x[i]\n",
        "        # else:\n",
        "        #     x[i] = (1 - w1) * x[i]\n",
        "        \n",
        "    r = np.zeros(n)\n",
        "    for i in range(n):\n",
        "        r[i] = sign_map[(S[i], v)]\n",
        "    #print('x: ', x)\n",
        "    #print('r: ', r)\n",
        "    #if (np.sum(x) == 0):\n",
        "    #    print('it is zero')\n",
        "    epsilon = 10 ** (-5)\n",
        "    #result = (np.dot(x.T, r)) / (np.sum(x) + epsilon)\n",
        "    result = (np.dot(x.T, r)) / (np.sum(x))\n",
        "    if result > threshold:\n",
        "        return 1\n",
        "    else:\n",
        "        return -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7784493",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec8bd279",
      "metadata": {
        "id": "ec8bd279"
      },
      "outputs": [],
      "source": [
        "# # Create a new column 'sign prediction' in test_df with sign predictions\n",
        "# def calculateSignPredictions(train_graph, main_clusters, test_df):\n",
        "#     with tqdm(total=len(test_df), desc=\"Calculating sign predictions\", bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}') as pbar:\n",
        "#         test_df['sign prediction'] = test_df.apply(lambda row: signPrediction(train_graph, main_clusters, matrix_of_similarity, 5, row['source'], row['target'], 0, 0.75), axis=1)\n",
        "#         pbar.update(len(test_df))  # Update the progress bar to complete\n",
        "\n",
        "#     return test_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b770bf8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a new column 'sign prediction' in test_df with sign predictions\n",
        "def calculateSignPredictions(train_graph, main_clusters, test_df, w):\n",
        "    new_test_df = test_df.copy()\n",
        "    tqdm.pandas()\n",
        "    new_test_df['sign prediction'] = new_test_df.progress_apply(lambda row: signPrediction(train_graph, main_clusters, matrix_of_similarity, 5, row['source'], row['target'], 0, w), axis=1)\n",
        "    return new_test_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd8ae6dd",
      "metadata": {
        "id": "cd8ae6dd",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# zz = np.zeros(test_df.shape[0])\n",
        "# # Call the function with the required parameters\n",
        "# new_test_df = calculateSignPredictions(train_graph, main_clusters, test_df, 0.75)\n",
        "# confusion_matrix(new_test_df['sign'], new_test_df['sign prediction'])\n",
        "# acc_temp = accuracy_score(new_test_df['sign'], new_test_df['sign prediction'],  normalize=True, sample_weight=None)\n",
        "# f_temp = f1_score(new_test_df['sign'], new_test_df['sign prediction'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "197eef23",
      "metadata": {
        "id": "197eef23"
      },
      "outputs": [],
      "source": [
        "# print(acc_temp)\n",
        "# print(f_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5dc47b9",
      "metadata": {
        "id": "e5dc47b9"
      },
      "outputs": [],
      "source": [
        "# plt.hist(test_df['sign'])\n",
        "\n",
        "# # Set the labels and title of the histogram\n",
        "# plt.xlabel('Sign')\n",
        "# plt.ylabel('Frequency')\n",
        "# plt.title('Histogram of Sign Values')\n",
        "\n",
        "# # Display the histogram\n",
        "# plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97d16830",
      "metadata": {
        "id": "97d16830"
      },
      "outputs": [],
      "source": [
        "acc_y = []\n",
        "f_y = []\n",
        "for w in [0.1, 0.3, 0.5, 0.7, 0.9, 1]:\n",
        "    new_test_df = calculateSignPredictions(train_graph, main_clusters, test_df, w)\n",
        "    confusion_matrix(new_test_df['sign'], new_test_df['sign prediction'])\n",
        "    acc_temp = accuracy_score(new_test_df['sign'], new_test_df['sign prediction'],  normalize=True, sample_weight=None)\n",
        "    f_temp = f1_score(new_test_df['sign'], new_test_df['sign prediction'])\n",
        "    print('acc:', acc_temp, 'f1:', f_temp)\n",
        "    acc_y.append(acc_temp)\n",
        "    f_y.append(f_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efdbf935",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
